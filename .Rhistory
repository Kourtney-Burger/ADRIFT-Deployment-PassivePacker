# Add Publication Date (this can be any date after deployment because these are data products)
dd$PUBLICATION_DATE <- '2024-03-01'
# Add site alias
for (i in 1:nrow(deployDetails)) {
dd$SITE_ALIAS[i] <- deployDetails$Site[i]
}
# Dataset Description
dd$PURPOSE <- 'ADRIFT in the California Current uses passive acoustic drifting buoys to study ocean sound in the California Current Ecosystem. The relatively low-cost buoys can be deployed and recovered from most vessels, including: research, fishing, and tourist boats. They drift autonomously and can be monitored shoreside via a satellite messenger. Data collected through the ADRIFT project will be used to assess noise levels and seasonal marine mammal acoustic presence in the California Current.'
dd$ABSTRACT <- ''
# Set package destination (change to appropriate file path)
dd$DESTINATION_PATH <- 'G:/Soundscape Metrics/Packaged Data'
for(i in 1:nrow(dd)) {
newQdList <- list(
'analyst' = deployDetails$Quality_Analyst[i],
'analyst_uuid' = '8f9f3e13-3571-436d-b1fd-6e779acd9a9f',
'quality_details' = list(
list(
'quality' = 'Good',
'low_freq' = deployDetails$Quality_LowFreq[i],
'high_freq' = deployDetails$Quality_HighFreq[i],
'start' = posixToText(deployDetails$Data_Start[i]),
'end' = posixToText(deployDetails$Data_End[i]),
'comments' = paste('Refer to ', deployDetails$Data_ID[i], '_500Hz_LF_Noise_Log.xls' , ' for detailed noise logs.', sep = ""),
'channels' = list(
1)
)
),
'method' = '',
'objectives' = '',
'abstract' = ''
)
# save newQdList to r list
dd$QUALITY_DETAILS[i] <- toJSON(newQdList)
}
#Comment once working
qdText <- '{"analyst": "Cory Hom-Weaver", "analyst_uuid": "8f9f3e13-3571-436d-b1fd-6e779acd9a9f", "quality_details": [{"quality": "Good", "low_freq": "250", "high_freq": "192000", "start": "2023-11-06T21:41:59", "end": "2023-11-10T21:10:00", "comments": "Refer to ADRIFT_108_500Hz_LF_Noise_Log.xls for detailed noise logs. ", "channels": [1]}], "method": "", "objectives": "", "abstract": ""}'
qdList <- fromJSON(qdText)
cat(toJSON(newQdList))
cat(toJSON(qdList))
#view(newQdList)
#View(qdList)
identical(newQdList,qdList)
for (i in 1:nrow(dd)) {
# for(i in 64) {
newSciList <- list(
list(
'name' = 'Anne Simonis',
'uuid' = '3e9e1d2e-0fed-45d0-bc21-c388d4ea933a'
)
)
dd$SCIENTISTS[i] <- toJSON(newSciList)
}
#Comment once working
# #Copy text from database
# sciText <- '[{"name": "Anne Simonis", "uuid": "3e9e1d2e-0fed-45d0-bc21-c388d4ea933a"}]'
# sciList <- fromJSON(sciText)
# cat(toJSON(newSciList))
# cat(toJSON(sciList))
# #view(newSciList)
# #View(sciList)
# identical(newSciList,sciList)
for (i in 1:nrow(dd)) {
#  for (i in 64) {
newSponList <- list(
list(
'name' = 'NOAA SWFSC',
'uuid' = '918a8687-8b33-4f70-b550-79a5273866fa'
)
)
dd$SPONSORS[i] <- toJSON(newSponList)
}
# # Comment once working
# # Copy text from database
# sponText <- '[{"name": "NOAA SWFSC", "uuid": "918a8687-8b33-4f70-b550-79a5273866fa"}]'
# sponList <- fromJSON(sponText)
# cat(toJSON(newSponList))
# cat(toJSON(sponList))
# #view(newSponList)
# #View(sponList)
# identical(newSponList,sponList)
for (i in 1:nrow(dd)) {
#  for (i in 64) {
newFunList <- list(
list(
'name' = 'NOAA SWFSC',
'uuid' = '918a8687-8b33-4f70-b550-79a5273866fa'
),
list(
'name' = 'BOEM',
'uuid' = 'fee4d17a-a7dd-4f13-ade5-817b4f1fc86d'
)
)
dd$FUNDERS[i] <- toJSON(newFunList)
}
# # Comment once working
# # Copy text from database
# funText <- '[{"name": "NOAA SWFSC", "uuid": "918a8687-8b33-4f70-b550-79a5273866fa"}, {"name": "BOEM", "uuid": "fee4d17a-a7dd-4f13-ade5-817b4f1fc86d"}]'
# funList <- fromJSON(funText)
# cat(toJSON(newFunList))
# cat(toJSON(funList))
# #view(newFunList)
# #View(funList)
# identical(newFunList,funList)
for(i in 1:nrow(dd)) {
#  for (i in 64) {
newDdList <- list(
'DEPLOY_TYPE' = 'Mobile Marine',
'SEA_AREA' = 'North Pacific Ocean',
'DEPLOY_SHIP' = deployDetails$Deploy.Vessel[i],
'FILES' = paste('G:/ADRIFT_RawData/manipulated/gps/',deployDetails$Data_ID[i],"/",deployDetails$Data_ID[i],'_GPS.csv',',','G:/ADRIFT_RawData/manipulated/gps/',deployDetails$Data_ID[i],'/',deployDetails$Data_ID[i],'_DeploymentDepth.csv', sep = ""),
'POSITION_DETAILS' = 'Solar Satellite GPS'
)
dd$DEPLOYMENT_DETAILS[i] <- toJSON(newDdList)
}
# # Comment once working
# # Copy text from database
# ddText <- '{"DEPLOY_TYPE": "Mobile Marine", "SEA_AREA": "North Pacific Ocean", "DEPLOY_SHIP": "R/V Shearwater", "FILES": "G:/ADRIFT_RawData/manipulated/gps/ADRIFT_108/ADRIFT_108_GPS.csv,G:/ADRIFT_RawData/manipulated/gps/ADRIFT_108/ADRIFT_108_DeploymentDepth.csv", "POSITION_DETAILS": "Solar Satellite GPS"}'
# ddList <- fromJSON(ddText)
# cat(toJSON(newDdList))
# cat(toJSON(ddList))
# #view(newDdList)
# #View(ddList)
# identical(newDdList,ddList)
for(i in 1:nrow(dd)) {
newCalList <- list(
'CAL_STATE' = 'Calibration applied before processing',
'CAL_DOCS_PATH' = paste("G:/Soundscape Metrics/Data/Manipulated/Cal files"),
'SENSITIVITY' = '',
'FREQUENCY' = '',
'GAIN' = '',
'COMMENT' = 'These sound level metrics were calculated from multiple Soundtraps (model 4300 and 640) with HTI-92WB hydrophones, each with its own unique sensitivity and frequency range. For the detailed calibration information refer to the SoundLevelMetrics_CalibrationInfo.csv spreadsheet.'
)
dd$CALIBRATION_INFO[i] <- toJSON(newCalList)
}
# # comment once working
# # Copy text from database
# calText <- '{"CAL_STATE": "Calibration applied before processing", "CAL_DOCS_PATH": "G:/Soundscape Metrics/Data/Manipulated/Cal files", "SENSITIVITY": "", "FREQUENCY": "", "GAIN": "", "COMMENT": "These sound level metrics were calculated from multiple Soundtraps (model 4300 and 640) with HTI-92WB hydrophones, each with its own unique sensitivity and frequency range. For the detailed calibration information refer to the SoundLevelMetrics_CalibrationInfo.csv spreadsheet."}'
# calList <- fromJSON(calText)
# cat(toJSON(newCalList))
# cat(toJSON(calList))
# #view(newCalList)
# #View(calList)
# identical(newCalList,calList)
for(i in 1:nrow(dd)) {
#  for (i in 81) {
newDiList <- list(
'TYPE' = 'Product',
'SUB_TYPE' = 'Sound Level Metrics',
'PLATFORM' = 'Drifter',
'INSTRUMENT_TYPE' = deployDetails$Type[i],
'INSTRUMENT_ID' = '',
'DEPLOYMENT_TIME' = '',
'RECOVERY_TIME' = '',
'AUDIO_START' = posixToText(as.POSIXct(SumMetadata$dataStart[i], tz='UTC')),
'AUDIO_END' = posixToText(as.POSIXct(SumMetadata$dataEnd[i], tz='UTC')),
'SOURCE_PATH' =  paste('G:/Soundscape Metrics/Data/RAW from DON/metrics/',deployDetails$Data_ID[i], sep = ""),
'DATA_FILES' = paste('G:/Soundscape Metrics/Data/RAW from DON/metrics/',deployDetails$Data_ID[i], sep = ""),
'ANALYSIS_TIME_ZONE' = '0',
'ANALYSIS_EFFORT' = '3600',
'MIN_ANALYSIS_FREQUENCY' = as.character(SumMetadata$LowBand[i]),
'MAX_ANALYSIS_FREQUENCY' = as.character(SumMetadata$HighBand[i]),
'ANALYSIS_SAMPLE_RATE' = '19200',
'SOFTWARE_NAME' = 'Triton-MATLAB',
'SOFTWARE_VERSION' = 'triton1.93.20160524',
'PROTOCOL_REFERENCE' = '',
'PROCESSING_STATEMENT' = 'The process to obtain these sound level metrics closely follows SanctSound protocols (https://sanctsound.ioos.us/). Triton software was used to decimate data to 48kHz and create long-term spectral averages (LTSAs) with a 1 Hz, 1 second resolution. These LTSAs were used to calculate sound levels in 2 minute windows from 100-24000 Hz. Median (50th percentile), mean, and various statistical sound levels (1st, 5th, 10th,25th, 75th, 90th, 95th percentiles) are calculated for each metric. For detailed methods, see our Soundscape analysis methods here https://sael-swfsc.github.io/adrift-analysis-methods/content/Soundscapes/Metrics.html.',
'SOFTWARE_STATEMENT' = 'The Soundscape Metric Remora within the Triton Software Package was used to calculate sound level metrics (https://github.com/MarineBioAcousticsRC/Triton/tree/master/Remoras/Soundscape-Metrics).',
'ANALYSIS_START' = posixToText(as.POSIXct(SumMetadata$dataStart[i], tz='UTC')),
'ANALYSIS_END' = posixToText(as.POSIXct(SumMetadata$dataEnd[i], tz='UTC'))
)
dd$DATASET_INFO[i] <- toJSON(newDiList)
}
# # comment once working
# # Copy text from database
# diText <- '{"TYPE": "Product", "SUB_TYPE": "Sound Level Metrics", "PLATFORM": "Drifter", "INSTRUMENT_TYPE": "SoundTrap 640", "INSTRUMENT_ID": "", "DEPLOYMENT_TIME": "", "RECOVERY_TIME": "", "AUDIO_START": "2023-11-06T13:42:00", "AUDIO_END": "2023-11-10T13:22:00", "SOURCE_PATH": "G:/Soundscape Metrics/Data/RAW from DON/metrics/ADRIFT_108", "DATA_FILES": "G:/Soundscape Metrics/Data/RAW from DON/metrics/ADRIFT_108", "ANALYSIS_TIME_ZONE": "0", "ANALYSIS_EFFORT": "3600", "MIN_ANALYSIS_FREQUENCY": "100", "MAX_ANALYSIS_FREQUENCY": "24000", "ANALYSIS_SAMPLE_RATE": "19200", "SOFTWARE_NAME": "Triton-MATLAB", "SOFTWARE_VERSION": "triton1.93.20160524", "PROTOCOL_REFERENCE": "", "PROCESSING_STATEMENT": "The process to obtain these sound level metrics closely follows SanctSound protocols (https://sanctsound.ioos.us/). Triton software was used to decimate data to 48kHz and create long-term spectral averages (LTSAs) with a 1 Hz, 1 second resolution. These LTSAs were used to calculate sound levels in 2 minute windows from 100-24000 Hz. Median (50th percentile), mean, and various statistical sound levels (1st, 5th, 10th,25th, 75th, 90th, 95th percentiles) are calculated for each metric. For detailed methods, see our Soundscape analysis methods here https://sael-swfsc.github.io/adrift-analysis-methods/content/Soundscapes/Metrics.html.", "SOFTWARE_STATEMENT": "The Soundscape Metric Remora within the Triton Software Package was used to calculate sound level metrics (https://github.com/MarineBioAcousticsRC/Triton/tree/master/Remoras/Soundscape-Metrics).", "ANALYSIS_START": "2023-11-06T13:42:00", "ANALYSIS_END": "2023-11-10T13:22:00"}'
# diList <- fromJSON(diText)
# cat(toJSON(newDiList))
# cat(toJSON(diList))
# #view(newDiList)
# #View(diList) #comment once running full loop
# identical(newDiList,diList)
paste('G:/ADRIFT_RawData/manipulated/metadata/',deployDetails$Data_ID.'/NoiseLogs')
paste('G:/ADRIFT_RawData/manipulated/metadata/',deployDetails$Data_ID[i],'/NoiseLogs')
paste('G:/ADRIFT_RawData/manipulated/metadata/',deployDetails$Data_ID[i],'/NoiseLogs', sep = "")
for(i in 1:nrow(dd)) {
#  for (i in 64) {
newAncilList <- list(
'BIO_PATH' = "",
'OTHER_PATH' = paste('G:/ADRIFT_RawData/manipulated/metadata/',deployDetails$Data_ID[i],'/NoiseLogs', sep = ""), #noise logs G:\ADRIFT_RawData\manipulated\metadata\ADRIFT_001\NoiseLogs
'TEMP_PATH' = ""
)
dd$ANCILLARY_INFO[i] <- toJSON(newAncilList)
}
for(i in 1:nrow(dd)) {
#  for (i in 64) {
newAncilList <- list(
'BIO_PATH' = "",
'OTHER_PATH' = paste('G:/ADRIFT_RawData/manipulated/metadata/',deployDetails$Data_ID[i],'/NoiseLogs', sep = ""), #noise logs G:\ADRIFT_RawData\manipulated\metadata\ADRIFT_001\NoiseLogs
'TEMP_PATH' = ""
)
dd$ANCILLARY_INFO[i] <- toJSON(newAncilList)
}
con <- dbConnect(SQLite(), here("PassivePacker_v.4.0.3-win64", "database", "packageData.sqlite"))
dbAppendTable(con, 'DEPLOYMENT_DATA', dd)
dbDisconnect(con)
#Noise logs
# List of files I want to move
currentNoise <- list.files(paste('Z:/RECORDINGS/DRIFTERS/ADRIFT/500Hz/',
deployDetails$Data_ID[i], '_500Hz', sep = ""),
pattern = "\\_Noise_Log.xls", full.names = T)
# Create folder/directory to move the list above to
dir.create(file.path(paste('G:/ADRIFT_RawData/manipulated/metadata/',
deployDetails$Data_ID[i], '/NoiseLogs', sep = "")))
newNoise <- file.path(paste('G:/ADRIFT_RawData/manipulated/metadata/',
deployDetails$Data_ID[i], '/NoiseLogs', sep = ""))
# Copy list of files to new directory
file.copy(currentNoise, newNoise)
library(here)
library(DBI)
library(RSQLite)
library(tidyverse)
library(rjson)
library(dplyr)
library(stringr)
DepDir <- here('ADRIFT-Deployment-PassivePacker/Soundscape Metrics')
posixToText <- function(x) {
format(x, '%Y-%m-%dT%H:%M:%S')
}
#TEST
#posixToText(as.POSIXct("2018-11-22 08:28:24", tz='UTC'))
deployDetails <- read.csv(here("DeploymentDetailsFiles","ADRIFT_DeploymentDetails.csv"))
# Read in additional metadata summarized from Soundscape metrics logs
SumMetadata <- read.csv("Adrift Data Summaries.csv")
# Subset to remove non ADRIFT deployments (do not need to run if only packaging ADRIFT deployments)
deployDetails <- subset(deployDetails, Project == "ADRIFT")
# Subset to remove planned, incomplete, and lost drifts
names(deployDetails)[10] <- "Status"
deployDetails <- subset(deployDetails, Status == "Complete")
# Subset to remove unusable drifts (Check data and ensure it cannot be used for ANYTHING, some 'bad' data could be used for high frequency)
deployDetails <- subset(deployDetails, Quality_Category != "Unusable")
# Subset any drifts that used SM2 or SM3 recorders
deployDetails <- subset(deployDetails, Type != c('SM2Bat','SM3M'))
# Remove any additional drifts that did not have sound level metrics calculated
deployDetails <- deployDetails[-c(2, 10, 15, 29, 35, 47, 50, 54, 62), ]
# Change soundtrap names
deployDetails[deployDetails == "ST640"] <- "SoundTrap 640"
deployDetails[deployDetails == "ST4300HF"] <- "SoundTrap 4300 High Frequency"
deployDetails[deployDetails == "ST300"] <- "SoundTrap 300"
deployDetails[deployDetails == "ST4300STD"] <- "SoundTrap 4300"
deployDetails[deployDetails == "ST500HF"] <- "SoundTrap 500 High Frequency"
deployDetails[deployDetails == "ST300HF"] <- "SoundTrap 300 High Frequency"
# Change Site Names
deployDetails[deployDetails == "WAS"] <- "Washington"
deployDetails[deployDetails == "COL"] <- "Columbia River"
deployDetails[deployDetails == "ORE"] <- "Oregon"
deployDetails[deployDetails == "HUM"] <- "Humboldt"
deployDetails[deployDetails == "MND"] <- "Mendocino"
deployDetails[deployDetails == "PTA"] <- "Point Arena"
deployDetails[deployDetails == "SFB"] <- "San Francisco Bay"
deployDetails[deployDetails == "HMB"] <- "Half Moon Bay"
deployDetails[deployDetails == "MBY"] <- "Monterey Bay"
deployDetails[deployDetails == "MOB"] <- "Morro Bay"
deployDetails[deployDetails == "CHI"] <- "Channel Islands"
deployDetails[deployDetails == "LAB"] <- "Los Angeles Basin"
deployDetails[deployDetails == "SND"] <- "San Diego"
deployDetails[deployDetails == "BCN"] <- "Baja California Norte"
deployDetails[deployDetails == "BCS"] <- "Baja California Sur"
# Fix date formats
# `format =` argument -> format needs to match the way the data is currently stored (should be %m/%d/%Y %H:%M:%S)
names(deployDetails)[37] <- "Data_Start"
names(deployDetails)[38] <- "Data_End"
deployDetails$Data_Start <- as.POSIXct(deployDetails$Data_Start, format = "%m/%d/%Y %H:%M:%S", tz = 'UTC')
deployDetails$Data_End <- as.POSIXct(deployDetails$Data_End, format = "%m/%d/%Y %H:%M:%S", tz = 'UTC')
deployDetails$Deployment_Date_UTC <- as.POSIXct(deployDetails$Deployment_Date_UTC, format = "%m/%d/%Y %H:%M", tz = 'UTC')
deployDetails$Recovery_Date_UTC <- as.POSIXct(deployDetails$Recovery_Date_UTC, format = "%m/%d/%Y %H:%M", tz = 'UTC')
deployDetails$Date..UTC <- as.Date(deployDetails$Date..UTC, "%m/%d/%Y")
# Reorder drifts
deployDetails <- deployDetails %>% arrange(DeploymentID)
# Make all data characters
deployDetails <- deployDetails %>%
mutate(across(where(is.numeric), as.character))
db <- dbConnect(SQLite(), here("PassivePacker_v.4.0.3-win64", "database", "packageData.sqlite"))
ppdt <- dbReadTable(db, "DEPLOYMENT_DATA")
dbDisconnect(db)
# Subset data
dd <- subset(deployDetails, select = c('Project', 'DeploymentID', 'Cruise'))
# Add required columns
# Change METADATA_AUTHOR and METADATA_AUTHOR_UUID to whoever is packaging data
# Change TITLE to full project name
dd <- dd %>%
add_column(ID = NA, SITE_CRUISE = NA, PACKAGE_ID = NA, SOURCE_PATH = NA,
DESTINATION_PATH = NA, METADATA_AUTHOR = 'Kourtney Burger',
META_AUTHOR_UUID = '2a603700-144e-442c-bbb5-27c40363819a',
PUBLICATION_DATE = NA, PLATFORM = NA, INSTRUMENT_TYPE = NA,
INSTRUMENT_ID = NA, DEPLOYMENT_ALIAS = NA, SITE_ALIAS = NA,
DEPLOY_TIME = NA, AUDIO_START_TIME = NA, RECOVER_TIME =NA,
AUDIO_END_TIME = NA, TITLE = "ADRIFT In the California Current",
PURPOSE = NA, ABSTRACT = NA, DATA_COMMENT = NA, TEMP_PATH = NA,
BIO_PATH = NA, OTHER_PATH = NA, DOCS_PATH = NA, CALIBRATION_PATH = NA,
CREATION_TIME = NA, UPDATE_TIME = NA, USE = 'Y', SAMPLING_DETAILS = NA,
QUALITY_DETAILS = NA, SCIENTISTS = NA, SPONSORS = NA, FUNDERS = NA,
SENSORS = NA, DEPLOYMENT_DETAILS = NA, CALIBRATION_INFO = NA,
DATASET_INFO = NA, ANCILLARY_INFO = NA)
# Reorder and rename columns
dd <- dd[, c(4,1,2,5,3,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,
26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42)]
names(dd)[2] <- "PROJECT"
names(dd)[3] <- "DEPLOYMENT_ID"
names(dd)[5] <- "SITE_OR_CRUISE"
# Add ID Number (Primary Key)
# If no existing data, maxID is 0
oldMax <- ifelse(nrow(ppdt) == 0, 0, max(ppdt$ID))
dd$ID <- (1:nrow(dd)) + oldMax
# Fix project and package_id fields
#(combine columns and remove spaces)
dd$PROJECT <- paste('["SWFSC-',dd$PROJECT,'"]')
dd$PACKAGE_ID <- paste('SWFSC-',SumMetadata$driftID,'-Soundscape')
dd$PROJECT <- gsub(" ","",dd$PROJECT)
dd$PACKAGE_ID <- gsub(" ","",dd$PACKAGE_ID)
# Add Publication Date (this can be any date after deployment because these are data products)
dd$PUBLICATION_DATE <- '2024-03-01'
# Add site alias
for (i in 1:nrow(deployDetails)) {
dd$SITE_ALIAS[i] <- deployDetails$Site[i]
}
# Dataset Description
dd$PURPOSE <- 'ADRIFT in the California Current uses passive acoustic drifting buoys to study ocean sound in the California Current Ecosystem. The relatively low-cost buoys can be deployed and recovered from most vessels, including: research, fishing, and tourist boats. They drift autonomously and can be monitored shoreside via a satellite messenger. Data collected through the ADRIFT project will be used to assess noise levels and seasonal marine mammal acoustic presence in the California Current.'
dd$ABSTRACT <- ''
# Set package destination (change to appropriate file path)
dd$DESTINATION_PATH <- 'G:/Soundscape Metrics/Packaged Data'
for(i in 1:nrow(dd)) {
newQdList <- list(
'analyst' = deployDetails$Quality_Analyst[i],
'analyst_uuid' = '8f9f3e13-3571-436d-b1fd-6e779acd9a9f',
'quality_details' = list(
list(
'quality' = 'Good',
'low_freq' = deployDetails$Quality_LowFreq[i],
'high_freq' = deployDetails$Quality_HighFreq[i],
'start' = posixToText(deployDetails$Data_Start[i]),
'end' = posixToText(deployDetails$Data_End[i]),
'comments' = paste('Refer to ', deployDetails$Data_ID[i], '_500Hz_LF_Noise_Log.xls' , ' for detailed noise logs.', sep = ""),
'channels' = list(
1)
)
),
'method' = '',
'objectives' = '',
'abstract' = ''
)
# save newQdList to r list
dd$QUALITY_DETAILS[i] <- toJSON(newQdList)
}
#Comment once working
qdText <- '{"analyst": "Cory Hom-Weaver", "analyst_uuid": "8f9f3e13-3571-436d-b1fd-6e779acd9a9f", "quality_details": [{"quality": "Good", "low_freq": "250", "high_freq": "192000", "start": "2023-11-06T21:41:59", "end": "2023-11-10T21:10:00", "comments": "Refer to ADRIFT_108_500Hz_LF_Noise_Log.xls for detailed noise logs. ", "channels": [1]}], "method": "", "objectives": "", "abstract": ""}'
qdList <- fromJSON(qdText)
cat(toJSON(newQdList))
cat(toJSON(qdList))
#view(newQdList)
#View(qdList)
identical(newQdList,qdList)
for (i in 1:nrow(dd)) {
# for(i in 64) {
newSciList <- list(
list(
'name' = 'Anne Simonis',
'uuid' = '3e9e1d2e-0fed-45d0-bc21-c388d4ea933a'
)
)
dd$SCIENTISTS[i] <- toJSON(newSciList)
}
#Comment once working
# #Copy text from database
# sciText <- '[{"name": "Anne Simonis", "uuid": "3e9e1d2e-0fed-45d0-bc21-c388d4ea933a"}]'
# sciList <- fromJSON(sciText)
# cat(toJSON(newSciList))
# cat(toJSON(sciList))
# #view(newSciList)
# #View(sciList)
# identical(newSciList,sciList)
for (i in 1:nrow(dd)) {
#  for (i in 64) {
newSponList <- list(
list(
'name' = 'NOAA SWFSC',
'uuid' = '918a8687-8b33-4f70-b550-79a5273866fa'
)
)
dd$SPONSORS[i] <- toJSON(newSponList)
}
# # Comment once working
# # Copy text from database
# sponText <- '[{"name": "NOAA SWFSC", "uuid": "918a8687-8b33-4f70-b550-79a5273866fa"}]'
# sponList <- fromJSON(sponText)
# cat(toJSON(newSponList))
# cat(toJSON(sponList))
# #view(newSponList)
# #View(sponList)
# identical(newSponList,sponList)
for (i in 1:nrow(dd)) {
#  for (i in 64) {
newFunList <- list(
list(
'name' = 'NOAA SWFSC',
'uuid' = '918a8687-8b33-4f70-b550-79a5273866fa'
),
list(
'name' = 'BOEM',
'uuid' = 'fee4d17a-a7dd-4f13-ade5-817b4f1fc86d'
)
)
dd$FUNDERS[i] <- toJSON(newFunList)
}
# # Comment once working
# # Copy text from database
# funText <- '[{"name": "NOAA SWFSC", "uuid": "918a8687-8b33-4f70-b550-79a5273866fa"}, {"name": "BOEM", "uuid": "fee4d17a-a7dd-4f13-ade5-817b4f1fc86d"}]'
# funList <- fromJSON(funText)
# cat(toJSON(newFunList))
# cat(toJSON(funList))
# #view(newFunList)
# #View(funList)
# identical(newFunList,funList)
for(i in 1:nrow(dd)) {
#  for (i in 64) {
newDdList <- list(
'DEPLOY_TYPE' = 'Mobile Marine',
'SEA_AREA' = 'North Pacific Ocean',
'DEPLOY_SHIP' = deployDetails$Deploy.Vessel[i],
'FILES' = paste('G:/ADRIFT_RawData/manipulated/gps/',deployDetails$Data_ID[i],"/",deployDetails$Data_ID[i],'_GPS.csv',',','G:/ADRIFT_RawData/manipulated/gps/',deployDetails$Data_ID[i],'/',deployDetails$Data_ID[i],'_DeploymentDepth.csv', sep = ""),
'POSITION_DETAILS' = 'Solar Satellite GPS'
)
dd$DEPLOYMENT_DETAILS[i] <- toJSON(newDdList)
}
# # Comment once working
# # Copy text from database
# ddText <- '{"DEPLOY_TYPE": "Mobile Marine", "SEA_AREA": "North Pacific Ocean", "DEPLOY_SHIP": "R/V Shearwater", "FILES": "G:/ADRIFT_RawData/manipulated/gps/ADRIFT_108/ADRIFT_108_GPS.csv,G:/ADRIFT_RawData/manipulated/gps/ADRIFT_108/ADRIFT_108_DeploymentDepth.csv", "POSITION_DETAILS": "Solar Satellite GPS"}'
# ddList <- fromJSON(ddText)
# cat(toJSON(newDdList))
# cat(toJSON(ddList))
# #view(newDdList)
# #View(ddList)
# identical(newDdList,ddList)
for(i in 1:nrow(dd)) {
newCalList <- list(
'CAL_STATE' = 'Calibration applied before processing',
'CAL_DOCS_PATH' = paste("G:/Soundscape Metrics/Data/Manipulated/Cal files"),
'SENSITIVITY' = '',
'FREQUENCY' = '',
'GAIN' = '',
'COMMENT' = 'These sound level metrics were calculated from multiple Soundtraps (model 4300 and 640) with HTI-92WB hydrophones, each with its own unique sensitivity and frequency range. For the detailed calibration information refer to the SoundLevelMetrics_CalibrationInfo.csv spreadsheet.'
)
dd$CALIBRATION_INFO[i] <- toJSON(newCalList)
}
# # comment once working
# # Copy text from database
# calText <- '{"CAL_STATE": "Calibration applied before processing", "CAL_DOCS_PATH": "G:/Soundscape Metrics/Data/Manipulated/Cal files", "SENSITIVITY": "", "FREQUENCY": "", "GAIN": "", "COMMENT": "These sound level metrics were calculated from multiple Soundtraps (model 4300 and 640) with HTI-92WB hydrophones, each with its own unique sensitivity and frequency range. For the detailed calibration information refer to the SoundLevelMetrics_CalibrationInfo.csv spreadsheet."}'
# calList <- fromJSON(calText)
# cat(toJSON(newCalList))
# cat(toJSON(calList))
# #view(newCalList)
# #View(calList)
# identical(newCalList,calList)
for(i in 1:nrow(dd)) {
#  for (i in 81) {
newDiList <- list(
'TYPE' = 'Product',
'SUB_TYPE' = 'Sound Level Metrics',
'PLATFORM' = 'Drifter',
'INSTRUMENT_TYPE' = deployDetails$Type[i],
'INSTRUMENT_ID' = '',
'DEPLOYMENT_TIME' = '',
'RECOVERY_TIME' = '',
'AUDIO_START' = posixToText(as.POSIXct(SumMetadata$dataStart[i], tz='UTC')),
'AUDIO_END' = posixToText(as.POSIXct(SumMetadata$dataEnd[i], tz='UTC')),
'SOURCE_PATH' =  paste('G:/Soundscape Metrics/Data/RAW from DON/metrics/',deployDetails$Data_ID[i], sep = ""),
'DATA_FILES' = paste('G:/Soundscape Metrics/Data/RAW from DON/metrics/',deployDetails$Data_ID[i], sep = ""),
'ANALYSIS_TIME_ZONE' = '0',
'ANALYSIS_EFFORT' = '3600',
'MIN_ANALYSIS_FREQUENCY' = as.character(SumMetadata$LowBand[i]),
'MAX_ANALYSIS_FREQUENCY' = as.character(SumMetadata$HighBand[i]),
'ANALYSIS_SAMPLE_RATE' = '19200',
'SOFTWARE_NAME' = 'Triton-MATLAB',
'SOFTWARE_VERSION' = 'triton1.93.20160524',
'PROTOCOL_REFERENCE' = '',
'PROCESSING_STATEMENT' = 'The process to obtain these sound level metrics closely follows SanctSound protocols (https://sanctsound.ioos.us/). Triton software was used to decimate data to 48kHz and create long-term spectral averages (LTSAs) with a 1 Hz, 1 second resolution. These LTSAs were used to calculate sound levels in 2 minute windows from 100-24000 Hz. Median (50th percentile), mean, and various statistical sound levels (1st, 5th, 10th,25th, 75th, 90th, 95th percentiles) are calculated for each metric. For detailed methods, see our Soundscape analysis methods here https://sael-swfsc.github.io/adrift-analysis-methods/content/Soundscapes/Metrics.html.',
'SOFTWARE_STATEMENT' = 'The Soundscape Metric Remora within the Triton Software Package was used to calculate sound level metrics (https://github.com/MarineBioAcousticsRC/Triton/tree/master/Remoras/Soundscape-Metrics).',
'ANALYSIS_START' = posixToText(as.POSIXct(SumMetadata$dataStart[i], tz='UTC')),
'ANALYSIS_END' = posixToText(as.POSIXct(SumMetadata$dataEnd[i], tz='UTC'))
)
dd$DATASET_INFO[i] <- toJSON(newDiList)
}
# # comment once working
# # Copy text from database
# diText <- '{"TYPE": "Product", "SUB_TYPE": "Sound Level Metrics", "PLATFORM": "Drifter", "INSTRUMENT_TYPE": "SoundTrap 640", "INSTRUMENT_ID": "", "DEPLOYMENT_TIME": "", "RECOVERY_TIME": "", "AUDIO_START": "2023-11-06T13:42:00", "AUDIO_END": "2023-11-10T13:22:00", "SOURCE_PATH": "G:/Soundscape Metrics/Data/RAW from DON/metrics/ADRIFT_108", "DATA_FILES": "G:/Soundscape Metrics/Data/RAW from DON/metrics/ADRIFT_108", "ANALYSIS_TIME_ZONE": "0", "ANALYSIS_EFFORT": "3600", "MIN_ANALYSIS_FREQUENCY": "100", "MAX_ANALYSIS_FREQUENCY": "24000", "ANALYSIS_SAMPLE_RATE": "19200", "SOFTWARE_NAME": "Triton-MATLAB", "SOFTWARE_VERSION": "triton1.93.20160524", "PROTOCOL_REFERENCE": "", "PROCESSING_STATEMENT": "The process to obtain these sound level metrics closely follows SanctSound protocols (https://sanctsound.ioos.us/). Triton software was used to decimate data to 48kHz and create long-term spectral averages (LTSAs) with a 1 Hz, 1 second resolution. These LTSAs were used to calculate sound levels in 2 minute windows from 100-24000 Hz. Median (50th percentile), mean, and various statistical sound levels (1st, 5th, 10th,25th, 75th, 90th, 95th percentiles) are calculated for each metric. For detailed methods, see our Soundscape analysis methods here https://sael-swfsc.github.io/adrift-analysis-methods/content/Soundscapes/Metrics.html.", "SOFTWARE_STATEMENT": "The Soundscape Metric Remora within the Triton Software Package was used to calculate sound level metrics (https://github.com/MarineBioAcousticsRC/Triton/tree/master/Remoras/Soundscape-Metrics).", "ANALYSIS_START": "2023-11-06T13:42:00", "ANALYSIS_END": "2023-11-10T13:22:00"}'
# diList <- fromJSON(diText)
# cat(toJSON(newDiList))
# cat(toJSON(diList))
# #view(newDiList)
# #View(diList) #comment once running full loop
# identical(newDiList,diList)
for(i in 1:nrow(dd)) {
#  for (i in 64) {
newAncilList <- list(
'BIO_PATH' = "",
'OTHER_PATH' = paste('G:/ADRIFT_RawData/manipulated/metadata/',deployDetails$Data_ID[i],'/NoiseLogs', sep = ""), #noise logs G:\ADRIFT_RawData\manipulated\metadata\ADRIFT_001\NoiseLogs
'TEMP_PATH' = ""
)
dd$ANCILLARY_INFO[i] <- toJSON(newAncilList)
}
con <- dbConnect(SQLite(), here("PassivePacker_v.4.0.3-win64", "database", "packageData.sqlite"))
dbAppendTable(con, 'DEPLOYMENT_DATA', dd)
dbDisconnect(con)
